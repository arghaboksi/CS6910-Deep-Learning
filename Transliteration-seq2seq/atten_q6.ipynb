{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J9ZhrUeTDsx-"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import keras.backend as K\n",
    "from tensorflow.keras import models\n",
    "from numpy import array_equal\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, SimpleRNN, GRU\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Input\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import io\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "import imageio\n",
    "import os   #This module provides a portable way of using operating system dependent functionality. \n",
    "from tqdm import tqdm_notebook as tqdm #used for progress bar in loops\n",
    "\n",
    "from IPython.display import HTML as html_print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dx0oFPzV5vpB",
    "outputId": "0b54da1f-9d9a-421c-f493-acf02a4b2498"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-08 12:36:30--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.147.128, 142.250.125.128, 142.250.148.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.147.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2008340480 (1.9G) [application/x-tar]\n",
      "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
      "\n",
      "dakshina_dataset_v1 100%[===================>]   1.87G   216MB/s    in 9.4s    \n",
      "\n",
      "2022-05-08 12:36:39 (205 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "!yes | wget \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6lF47Fe9fvcH"
   },
   "outputs": [],
   "source": [
    "# Unzip\n",
    "!yes | tar xopf dakshina_dataset_v1.0.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "an0uSRI_xQOl"
   },
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import FontProperties\n",
    "hi_font = FontProperties(fname = 'nirmala.ttf', size=18) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PBzvL2e20Sx-",
    "outputId": "3ba891a4-b59f-4df2-fd48-5894e146ef55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train:  44204\n",
      "Numb val:  4358\n",
      "Num test:  4502\n"
     ]
    }
   ],
   "source": [
    "train = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
    "val = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\"\n",
    "test = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\"\n",
    "def dataset(data_file):\n",
    "    hindi = []\n",
    "    latin = []\n",
    "    with io.open(data_file, encoding ='utf-8') as f:\n",
    "        for line in f:\n",
    "            if '\\t' not in line:\n",
    "                continue\n",
    "            tokens = line.rstrip().split(\"\\t\")\n",
    "            latin.append(tokens[1])\n",
    "            hindi.append(tokens[0])\n",
    "    return latin, hindi\n",
    "\n",
    "tr_src, tr_trgt = dataset(train)\n",
    "val_src, val_trgt = dataset(val)\n",
    "ts_src, ts_trgt = dataset(test)\n",
    "\n",
    "print(\"Num train: \", len(tr_src))\n",
    "print(\"Numb val: \", len(val_src))\n",
    "print(\"Num test: \", len(ts_src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgxYhZkv53Rl",
    "outputId": "0ae96f3f-6534-484f-fc20-f2205c81b924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 44204\n",
      "Number of unique input tokens: 27\n",
      "Number of unique output tokens: 66\n",
      "Max sequence length for inputs: 20\n",
      "Max sequence length for outputs: 21\n",
      "Max sequence length for val inputs: 18\n",
      "Max sequence length for val outputs: 16\n",
      "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "[' ', 'B', 'E', 'ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह', '़', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्', 'ॐ']\n"
     ]
    }
   ],
   "source": [
    "iter_tr = np.arange(len(tr_src))\n",
    "np.random.shuffle(iter_tr)\n",
    "iter_val = np.arange(len(val_src))\n",
    "np.random.shuffle(iter_val)\n",
    "\n",
    "char_inpts = set()\n",
    "char_tar = set()\n",
    "text_inpts = []\n",
    "text_trgts = []\n",
    "inpts_val = []\n",
    "trgts_val = []\n",
    "\n",
    "for (txt_inp, target_text) in zip(tr_src, tr_trgt):\n",
    "    target_text = \"B\" + target_text + \"E\"\n",
    "    text_inpts.append(txt_inp)\n",
    "    text_trgts.append(target_text)\n",
    "    for char in txt_inp:\n",
    "        if char not in char_inpts:\n",
    "            char_inpts.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in char_tar:\n",
    "            char_tar.add(char)\n",
    "\n",
    "for (txt_inp, target_text) in zip(val_src, val_trgt):\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = \"B\" + target_text + \"E\"\n",
    "    inpts_val.append(txt_inp)\n",
    "    trgts_val.append(target_text)\n",
    "    for char in txt_inp:\n",
    "        if char not in char_inpts:\n",
    "            char_inpts.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in char_tar:\n",
    "            char_tar.add(char)\n",
    "\n",
    "txt_inps = []\n",
    "txt_trgt = []\n",
    "\n",
    "for i in range(len(tr_src)):\n",
    "    txt_inps.append(text_inpts[iter_tr[i]])\n",
    "    txt_trgt.append(text_trgts[iter_tr[i]])\n",
    "\n",
    "txt_inps_val = []\n",
    "txt_trgt_val = []\n",
    "\n",
    "for i in range(len(val_src)):\n",
    "    txt_inps_val.append(inpts_val[iter_val[i]])\n",
    "    txt_trgt_val.append(trgts_val[iter_val[i]])\n",
    "\n",
    "char_inpts.add(\" \")\n",
    "char_tar.add(\" \")\n",
    "\n",
    "char_inpts = sorted(list(char_inpts))\n",
    "char_tar = sorted(list(char_tar))\n",
    "\n",
    "enc_num = len(char_inpts)\n",
    "dec_num = len(char_tar)\n",
    "enc_mx = max([len(txt) for txt in txt_inps])\n",
    "dec_mx = max([len(txt) for txt in txt_trgt])\n",
    "enc_mx_val = max([len(txt) for txt in txt_inps_val])\n",
    "dec_mx_val = max([len(txt) for txt in txt_trgt_val])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Num samples:\", len(txt_inps))\n",
    "print(\"Number of unique input tokens:\", enc_num)\n",
    "print(\"Number of unique output tokens:\", dec_num)\n",
    "print(\"Max sequence length for inputs:\", enc_mx)\n",
    "print(\"Max sequence length for outputs:\", dec_mx)\n",
    "print(\"Max sequence length for val inputs:\", enc_mx_val)\n",
    "print(\"Max sequence length for val outputs:\", dec_mx_val)\n",
    "\n",
    "print(char_inpts)\n",
    "print(char_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OtHaPQPw6VuP",
    "outputId": "a13fb08f-03ab-4b74-d883-3e8b3d55ffb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
      "{' ': 0, 'B': 1, 'E': 2, 'ँ': 3, 'ं': 4, 'ः': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ए': 13, 'ऐ': 14, 'ऑ': 15, 'ओ': 16, 'औ': 17, 'क': 18, 'ख': 19, 'ग': 20, 'घ': 21, 'ङ': 22, 'च': 23, 'छ': 24, 'ज': 25, 'झ': 26, 'ञ': 27, 'ट': 28, 'ठ': 29, 'ड': 30, 'ढ': 31, 'ण': 32, 'त': 33, 'थ': 34, 'द': 35, 'ध': 36, 'न': 37, 'प': 38, 'फ': 39, 'ब': 40, 'भ': 41, 'म': 42, 'य': 43, 'र': 44, 'ल': 45, 'व': 46, 'श': 47, 'ष': 48, 'स': 49, 'ह': 50, '़': 51, 'ा': 52, 'ि': 53, 'ी': 54, 'ु': 55, 'ू': 56, 'ृ': 57, 'ॅ': 58, 'े': 59, 'ै': 60, 'ॉ': 61, 'ो': 62, 'ौ': 63, '्': 64, 'ॐ': 65}\n"
     ]
    }
   ],
   "source": [
    "idx_inp = dict([(char, i) for i, char in enumerate(char_inpts)])\n",
    "idx_tar = dict([(char, i) for i, char in enumerate(char_tar)])\n",
    "idx_inp_rev = dict((i, char) for char, i in idx_inp.items())\n",
    "idx_tar_rev = dict((i, char) for char, i in idx_tar.items())\n",
    "print(idx_inp)\n",
    "print(idx_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CtAojV-O6p0G"
   },
   "outputs": [],
   "source": [
    "txt_inp_sl = txt_inps[:44160]\n",
    "txt_tar_sl = txt_trgt[:44160]\n",
    "\n",
    "inp_enc = np.zeros(\n",
    "    (len(txt_inp_sl), enc_mx, enc_num), dtype=\"float64\"\n",
    ")\n",
    "tar_dec = np.zeros(\n",
    "    (len(txt_inp_sl), dec_mx, dec_num), dtype=\"float64\"\n",
    ")\n",
    "\n",
    "for i, (txt_inp, target_text) in enumerate(zip(txt_inp_sl, txt_tar_sl)):\n",
    "    for t, char in enumerate(txt_inp):\n",
    "        inp_enc[i, t, idx_inp[char]] = 1.0\n",
    "    inp_enc[i, t + 1 :, idx_inp[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        tar_dec[i, t, idx_tar[char]] = 1.0\n",
    "    tar_dec[i, t + 1 :, idx_tar[\" \"]] = 1.0\n",
    "    \n",
    "inp_enc_val = np.zeros(\n",
    "    (len(txt_inps_val), enc_mx, enc_num), dtype=\"float64\"\n",
    ")\n",
    "tar_dec_val = np.zeros(\n",
    "    (len(txt_trgt_val), dec_mx, dec_num), dtype=\"float64\"\n",
    ")\n",
    "\n",
    "for i, (txt_inp, target_text) in enumerate(zip(txt_inps_val, txt_trgt_val)):\n",
    "    for t, char in enumerate(txt_inp):\n",
    "        inp_enc_val[i, t, idx_inp[char]] = 1.0\n",
    "    inp_enc_val[i, t + 1 :, idx_inp[\" \"]] = 1.0\n",
    "\n",
    "    for t, char in enumerate(target_text):\n",
    "        tar_dec_val[i, t, idx_tar[char]] = 1.0\n",
    "    tar_dec_val[i, t + 1: ,idx_tar[\" \"]] = 1.0\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vx8rEIqmMQNT"
   },
   "source": [
    "# ATTENTION MECHANISM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "N-RyyRhTQ2XC"
   },
   "outputs": [],
   "source": [
    "class atten_badh(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(atten_badh, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        qwt_ax = tf.expand_dims(query, 1)\n",
    "\n",
    "        sc = self.V(tf.nn.tanh(\n",
    "            self.W1(qwt_ax) + self.W2(values)))\n",
    "        att_w = tf.nn.softmax(sc, axis=1)\n",
    "        c_v = att_w * values\n",
    "        c_v = tf.reduce_sum(c_v, axis=1)\n",
    "        return c_v, att_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2mfk2-afoCeE"
   },
   "outputs": [],
   "source": [
    "class seq_atten(object):\n",
    "    def __init__(self,ty = 'RNN', hs=32, \n",
    "                   lr= 1e-3,drp=0.3,epochs = 10, bs = 32,\n",
    "                   atten = 'bahd'):\n",
    "\n",
    "        self.ty = ty\n",
    "        self.hs = hs\n",
    "        self.lr = lr\n",
    "        self.drp = drp\n",
    "        self.epochs = epochs\n",
    "        self.bs = bs\n",
    "        self.atten = atten\n",
    "\n",
    "    def fit(self,inp_enc,tar_dec):\n",
    "\n",
    "        enc_inp_temp = Input(shape=(enc_mx, enc_num), name='enc_inp_temp')\n",
    "        if self.ty == 'LSTM':\n",
    "            enc_lstm = LSTM(self.hs,ret_seq=True, return_state=True, drp = self.drp, name='enc_lstm')\n",
    "            enc_outputs, enc_state_h, enc_state_c = enc_lstm(enc_inp_temp)\n",
    "            enc_states = [enc_state_h, enc_state_c]\n",
    "        elif self.ty == 'GRU':\n",
    "            enc_gru = GRU(self.hs,ret_seq=True, return_state=True, drp = self.drp, name='enc_gru')\n",
    "            enc_outputs, enc_state_h = enc_gru(enc_inp_temp)\n",
    "            enc_states = [enc_state_h]\n",
    "        elif self.ty == 'RNN':\n",
    "            enc_rnn = SimpleRNN(self.hs,ret_seq=True, return_state=True, drp = self.drp, name='enc_rnn')\n",
    "            enc_outputs, enc_state_h = enc_rnn(enc_inp_temp)\n",
    "            enc_states = [enc_state_h]\n",
    "\n",
    "        if self.atten == 'bahd':\n",
    "            atten= atten_badh(self.hs)\n",
    "\n",
    "        dec_inputs = Input(shape=(1, (dec_num+self.hs)),name='dec_inputs')\n",
    "        if self.ty== 'LSTM':\n",
    "            dec_lstm = LSTM(self.hs, drp = self.drp, return_state=True, name='dec_lstm')\n",
    "        elif self.ty == 'GRU':\n",
    "            dec_gru = GRU(self.hs, drp = self.drp, return_state=True, name='dec_gru')\n",
    "        elif self.ty == 'RNN':\n",
    "            dec_rnn = SimpleRNN(self.hs, drp = self.drp, return_state=True, name='dec_rnn')  \n",
    "\n",
    "        dec_dense = Dense(dec_num, activation='softmax',  name='dec_dense')\n",
    "\n",
    "        all_outputs = []\n",
    "\n",
    "        inputs = np.zeros((self.bs, 1, dec_num))\n",
    "        inputs[:, 0, 0] = 1 \n",
    "\n",
    "        dec_outputs = enc_state_h\n",
    "        states = enc_states\n",
    "\n",
    "        for _ in range(dec_mx):\n",
    "\n",
    "            con_vec, atten_weights=atten(dec_outputs, enc_outputs)\n",
    "\n",
    "            con_vec = tf.expand_dims(con_vec, 1)\n",
    "\n",
    "            inputs = tf.concat([con_vec, inputs], axis=-1)\n",
    "            if self.ty == 'LSTM':\n",
    "                dec_outputs, state_h, state_c = dec_lstm(inputs, initial_state=states)\n",
    "            if self.ty == 'GRU':\n",
    "                dec_outputs, state_h = dec_gru(inputs, initial_state=states)\n",
    "            if self.ty == 'RNN':\n",
    "                dec_outputs, state_h = dec_rnn(inputs, initial_state=states)\n",
    "\n",
    "            outputs = dec_dense(dec_outputs)\n",
    "            outputs = tf.expand_dims(outputs, 1)\n",
    "            all_outputs.append(outputs)\n",
    "            inputs = outputs\n",
    "            if self.ty == 'LSTM':\n",
    "                states = [state_h, state_c]\n",
    "            if self.ty == 'GRU' or self.ty == 'RNN':\n",
    "                states = [state_h]\n",
    "\n",
    "\n",
    "        dec_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
    "\n",
    "        model = Model(enc_inp_temp, dec_outputs, name='model_enc_dec')\n",
    "\n",
    "        optimizer = Adam(lr=self.lr, beta_1=0.9, beta_2=0.999)\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        #model.summary()\n",
    "\n",
    "        model.fit(inp_enc, tar_dec,\n",
    "                  bs=self.bs, \n",
    "                  epochs=self.epochs,\n",
    "                  )\n",
    "        if self.ty== 'LSTM':\n",
    "            return enc_lstm,atten,dec_lstm,dec_dense\n",
    "        if self.ty == 'GRU':\n",
    "            return enc_gru,atten,dec_gru,dec_dense\n",
    "        if self.ty== 'RNN':\n",
    "            return enc_rnn,atten,dec_rnn,dec_dense  \n",
    "\n",
    "    def evaluate(self,seq_in):\n",
    "        atten_plot = np.zeros((dec_mx, enc_mx))\n",
    "        sequence = seq_in\n",
    "        enc_inp_temp=array(sequence).reshape(1,enc_mx,enc_num)\n",
    "\n",
    "        enc_inp_temp = tf.convert_to_tensor(enc_inp_temp,dtype=tf.float32)\n",
    "\n",
    "        if self.ty == 'LSTM':\n",
    "            enc_outputs, enc_state_h, enc_state_c = enc(enc_inp_temp)\n",
    "            enc_states = [enc_state_h, enc_state_c]\n",
    "        elif self.ty == 'GRU':\n",
    "            enc_outputs, enc_state_h = enc(enc_inp_temp)\n",
    "            enc_states = [enc_state_h]\n",
    "        elif self.ty == 'RNN':\n",
    "            enc_outputs, enc_state_h = enc(enc_inp_temp)\n",
    "            enc_states = [enc_state_h]\n",
    "\n",
    "        all_outputs = []\n",
    "\n",
    "        dec_input_data = np.zeros((1, 1, dec_num))\n",
    "        dec_input_data[:, 0, 0] = 1 \n",
    "\n",
    "        inputs = dec_input_data\n",
    "        dec_outputs = enc_state_h\n",
    "        states = enc_states\n",
    "\n",
    "        weigh_atten =[]\n",
    "        for t in range(dec_mx):\n",
    "            con_vec, atten_weights = atten(dec_outputs, enc_outputs)\n",
    "\n",
    "            atten_weights = tf.reshape(atten_weights, (-1, ))\n",
    "            weigh_atten.append(atten_weights)\n",
    "\n",
    "            atten_plot[t] = atten_weights.numpy()\n",
    "\n",
    "            dec_outputs=tf.expand_dims(dec_outputs, 1)\n",
    "\n",
    "            con_vec = tf.expand_dims(con_vec, 1)\n",
    "            inputs = tf.concat([con_vec, inputs], axis=-1)\n",
    "\n",
    "            if self.ty == 'LSTM':\n",
    "                dec_outputs, state_h, state_c = dec(inputs, initial_state=states)\n",
    "            if self.ty == 'GRU':\n",
    "                dec_outputs, state_h = dec(inputs, initial_state=states)\n",
    "            if self.ty == 'RNN':\n",
    "                dec_outputs, state_h = dec(inputs, initial_state=states)\n",
    "\n",
    "            outputs = dec_dense(dec_outputs)\n",
    "            outputs = tf.expand_dims(outputs, 1)\n",
    "            all_outputs.append(outputs)\n",
    "            inputs = outputs\n",
    "            if self.ty == 'LSTM':\n",
    "                states = [state_h, state_c]\n",
    "            if self.ty == 'GRU' or self.ty == 'RNN':\n",
    "                states = [state_h]\n",
    "\n",
    "        dec_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
    "        seq_outs = dec_outputs[0]\n",
    "        seq_out = tf.argmax(seq_outs, axis=1)\n",
    "        seq_out = seq_out.numpy()\n",
    "        seq_in = tf.argmax(seq_in, axis = 1)\n",
    "        seq_in = seq_in.numpy()\n",
    "        list(filter(lambda num: num != 0, seq_in))\n",
    "        list(filter(lambda num: num != 0, seq_out))\n",
    "\n",
    "        return seq_in, seq_out, atten_plot, weigh_atten\n",
    "\n",
    "    def plot_atten(self,atten, sequence, predicted_sequence):\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.matshow(atten, cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 30}\n",
    "        seq = ''\n",
    "        for i in range(len(sequence)):\n",
    "            seq = seq + idx_inp_rev[sequence[i]]\n",
    "\n",
    "        pred = ''\n",
    "        for i in range(len(predicted_sequence)):\n",
    "            pred = pred + idx_tar_rev[predicted_sequence[i]]\n",
    "        print(pred)\n",
    "        #ax.rcParams[\"font.family\"] = \"Vijaya\"\n",
    "        ax.set_xticklabels(seq, fontdict=fontdict)\n",
    "        ax.set_yticklabels(pred, fontdict=fontdict, fontproperties = hi_font)\n",
    "\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def translate(self,seq_in):\n",
    "        seq_in, seq_out, atten_plot, weigh_atten = self.evaluate(seq_in)\n",
    "\n",
    "        a = [0]\n",
    "        for i in range(len(seq_in)):\n",
    "              if seq_in[i] != 0:\n",
    "                a.append(seq_in[i])\n",
    "\n",
    "        b = []\n",
    "        for i in range(len(seq_out)):\n",
    "              if seq_out[i] != 0:\n",
    "                b.append(seq_out[i])\n",
    "\n",
    "        b = b[:len(b)-1]\n",
    "        print(a)\n",
    "        print(b)\n",
    "\n",
    "        atten_plot = atten_plot[:len(b), :len(a)]\n",
    "        self.plot_atten(atten_plot, a, b)  \n",
    "\n",
    "        return weigh_atten\n",
    "\n",
    "    def atten_plot(self,val_input):\n",
    "        seq_in = val_input\n",
    "        weigh_atten = self.translate(seq_in)  \n",
    "        return weigh_atten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3H8C__mqymd-"
   },
   "outputs": [],
   "source": [
    "model = seq_atten(ty = 'LSTM', hs=128, lr= 1e-3,\n",
    "                        drp=0.2,epochs = 15, bs = 128, atten = 'bahd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2iRrBYTEoCh",
    "outputId": "67375526-5b5d-41a0-8062-e65bc0dd17c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "345/345 [==============================] - 99s 164ms/step - loss: 1.3121 - accuracy: 0.6806\n",
      "Epoch 2/15\n",
      "345/345 [==============================] - 56s 163ms/step - loss: 1.1182 - accuracy: 0.7023\n",
      "Epoch 3/15\n",
      "345/345 [==============================] - 57s 164ms/step - loss: 1.0403 - accuracy: 0.7145\n",
      "Epoch 4/15\n",
      "345/345 [==============================] - 56s 164ms/step - loss: 0.9718 - accuracy: 0.7268\n",
      "Epoch 5/15\n",
      "345/345 [==============================] - 57s 164ms/step - loss: 0.9147 - accuracy: 0.7381\n",
      "Epoch 6/15\n",
      "345/345 [==============================] - 56s 163ms/step - loss: 0.8663 - accuracy: 0.7493\n",
      "Epoch 7/15\n",
      "345/345 [==============================] - 56s 163ms/step - loss: 0.8277 - accuracy: 0.7581\n",
      "Epoch 8/15\n",
      "345/345 [==============================] - 56s 164ms/step - loss: 0.7947 - accuracy: 0.7660\n",
      "Epoch 9/15\n",
      "345/345 [==============================] - 56s 163ms/step - loss: 0.7648 - accuracy: 0.7729\n",
      "Epoch 10/15\n",
      "345/345 [==============================] - 56s 164ms/step - loss: 0.7355 - accuracy: 0.7803\n",
      "Epoch 11/15\n",
      "345/345 [==============================] - 56s 163ms/step - loss: 0.7116 - accuracy: 0.7858\n",
      "Epoch 12/15\n",
      "345/345 [==============================] - 57s 164ms/step - loss: 0.6865 - accuracy: 0.7920\n",
      "Epoch 13/15\n",
      "345/345 [==============================] - 56s 164ms/step - loss: 0.6678 - accuracy: 0.7970\n",
      "Epoch 14/15\n",
      "345/345 [==============================] - 56s 164ms/step - loss: 0.6486 - accuracy: 0.8024\n",
      "Epoch 15/15\n",
      "345/345 [==============================] - 56s 164ms/step - loss: 0.6333 - accuracy: 0.8060\n"
     ]
    }
   ],
   "source": [
    "enc,atten,dec,dec_dense = model.fit(inp_enc,tar_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "iB36aNtQuBwh",
    "outputId": "000ef69a-0dcc-45a6-e22b-9c57c9751f60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 19, 21, 18, 1, 11, 19, 8, 9, 20]\n",
      "[1, 49, 55, 44, 52, 64, 48, 48, 33]\n",
      "Bसुरा्षषत\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_a = model.atten_plot(inp_enc_val[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "jwHk7AfmgQGb"
   },
   "outputs": [],
   "source": [
    "def cstr(s, color='black'):\n",
    "\tif s == ' ':\n",
    "\t\treturn \"<text style=color:#000;padding-left:10px;background-color:{}> </text>\".format(color, s)\n",
    "\telse:\n",
    "\t\treturn \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n",
    "\t\n",
    "# print html\n",
    "def print_color(t):\n",
    "\tdisplay(html_print(''.join([cstr(ti, color=ci) for ti,ci in t])))\n",
    "\n",
    "# get appropriate color for value\n",
    "def get_clr(value):\n",
    "\tcolors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8'\n",
    "\t\t'#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
    "\t\t'#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
    "\t\t'#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
    "\tvalue = int((value * 100) / 5)\n",
    "\treturn colors[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8sUQVtFDis1-",
    "outputId": "8e76d9d3-524f-4d54-8caf-d34aadf71a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surakshit\n",
      "सुरा्षषत\n",
      "9\n",
      "8\n",
      "स\n",
      "ु\n",
      "र\n",
      "ा\n",
      "्\n",
      "ष\n",
      "ष\n",
      "त\n"
     ]
    }
   ],
   "source": [
    "eng = [19, 21, 18, 1, 11, 19, 8, 9, 20]\n",
    "hin = [49, 55, 44, 52, 64, 48, 48, 33]\n",
    "\n",
    "eng_rev = ''\n",
    "for i in range(len(eng)):\n",
    "    eng_rev = eng_rev + idx_inp_rev[eng[i]]\n",
    "\n",
    "hin_rev = ''\n",
    "for i in range(len(hin)):\n",
    "    hin_rev = hin_rev + idx_tar_rev[hin[i]]\n",
    "\n",
    "print(eng_rev) \n",
    "print(hin_rev)\n",
    "\n",
    "len_eng = len(eng)\n",
    "len_hin = len(hin)\n",
    "print(len_eng)\n",
    "print(len_hin)\n",
    "\n",
    "for i in range(len(hin)):\n",
    "    print(idx_tar_rev[hin[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "ySjsQhyiiFWW"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def visualize(output_values, result_list,k):\n",
    "    text_colours = []\n",
    "    for i in range(len_eng):\n",
    "        text = (result_list[i], get_clr(output_values[i]))\n",
    "        text_colours.append(text)\n",
    "        if i == len_eng-1:\n",
    "            html_file = open(str(k)+\".html\", \"w\")\n",
    "            html_file.write(''.join([cstr(ti, color=ci) for ti,ci in text_colours]))\n",
    "            html_file.close()\n",
    "            display(html_print(''.join([cstr(ti, color=ci) for ti,ci in text_colours])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "YUW0qHO_iWEp"
   },
   "outputs": [],
   "source": [
    "for j in range(len_hin):\n",
    "    visualize(w_a[j][:], eng_rev,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yzbeu1fILc0-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "atten_mem_viz.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
