{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JNwYz3rgvbvN"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from random import randint\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from numpy import array, argmax, array_equal \n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import models, Input\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, SimpleRNN, GRU, Dense, Flatten, TimeDistributed, RepeatVector, Lambda\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "tf.keras.backend.set_floatx('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XU3jSjNIw1m9"
      },
      "outputs": [],
      "source": [
        "#%pip install wandb -q\n",
        "#import wandb\n",
        "#from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoCuGoIhw1qN"
      },
      "outputs": [],
      "source": [
        "#wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv4hMiKQw1sm"
      },
      "outputs": [],
      "source": [
        "#wandb.init(project=\"Assignment 3\", entity=\"shubham-argha\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18tCLa_Bw1vC",
        "outputId": "4bb6257c-fdab-4948-9e20-39430eccc482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-08 10:58:51--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.147.128, 142.250.125.128, 142.250.136.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.147.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   121MB/s    in 17s     \n",
            "\n",
            "2022-05-08 10:59:07 (114 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Dataset\n",
        "!yes | wget \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ucdg-ZdZw1xU"
      },
      "outputs": [],
      "source": [
        "# Unzip\n",
        "!yes | tar xopf dakshina_dataset_v1.0.tar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
        "test_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\""
      ],
      "metadata": {
        "id": "5N6ushcHTvVi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w37EvAfN0s1f"
      },
      "outputs": [],
      "source": [
        "# reads text document and returns a list of lists comprising the romanized and native versions of the words\n",
        "def read(f):\n",
        "    hindi = []\n",
        "    latin = []\n",
        "    with io.open(f, encoding ='utf-8') as f:\n",
        "        for line in f:\n",
        "            if '\\t' not in line:\n",
        "                continue\n",
        "            tokens = line.rstrip().split(\"\\t\")\n",
        "            latin.append(tokens[1])\n",
        "            hindi.append(tokens[0])\n",
        "    return latin, hindi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_src, tr_tar = read(train_dir)\n",
        "tst_src, tst_tar = read(test_dir)"
      ],
      "metadata": {
        "id": "rNsJDJ5LU_6W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of training samples: \", len(tr_src))\n",
        "print(\"Number of testing samples: \", len(tst_src))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEoutLZ-VJZ5",
        "outputId": "695ceea4-48cf-4189-ba46-dffbbdaf2961"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples:  44204\n",
            "Number of testing samples:  4502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.arange(len(tr_src))\n",
        "np.random.shuffle(A)\n",
        "A1 = np.arange(len(tst_src))\n",
        "np.random.shuffle(A1)"
      ],
      "metadata": {
        "id": "vDm_-A1CVaAT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_inp = set()\n",
        "char_tar = set()\n",
        "ns_txt_inp = []\n",
        "ns_txt_tar = []\n",
        "ns_txt_inp_tst = []\n",
        "ns_txt_tar_tst = []"
      ],
      "metadata": {
        "id": "_KEq8aOkVaCl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (txt_inp, txt_tar) in zip(tr_src, tr_tar):\n",
        "\n",
        "    txt_tar = \"B\" + txt_tar + \"E\"\n",
        "    ns_txt_inp.append(txt_inp)\n",
        "    ns_txt_tar.append(txt_tar)\n",
        "    for char in txt_inp:\n",
        "        if char not in char_inp:\n",
        "            char_inp.add(char)\n",
        "    for char in txt_tar:\n",
        "        if char not in char_tar:\n",
        "            char_tar.add(char)"
      ],
      "metadata": {
        "id": "ECVNS0SLVaE3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (txt_inp, txt_tar) in zip(tst_src, tst_tar):\n",
        "    txt_tar = \"B\" + txt_tar + \"E\"\n",
        "    ns_txt_inp_tst.append(txt_inp)\n",
        "    ns_txt_tar_tst.append(txt_tar)\n",
        "    for char in txt_inp:\n",
        "        if char not in char_inp:\n",
        "            char_inp.add(char)\n",
        "    for char in txt_tar:\n",
        "        if char not in char_tar:\n",
        "            char_tar.add(char)"
      ],
      "metadata": {
        "id": "4IQvSx0NVaHC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inps_txt = []\n",
        "tars_txt = []\n",
        "\n",
        "for i in range(len(tr_src)):\n",
        "    inps_txt.append(ns_txt_inp[A[i]])\n",
        "    tars_txt.append(ns_txt_tar[A[i]])\n"
      ],
      "metadata": {
        "id": "kZm52b0SVaJV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inps_txt_tst = []\n",
        "txt_tar_tst = []\n",
        "\n",
        "for i in range(len(tst_src)):\n",
        "    inps_txt_tst.append(ns_txt_inp_tst[A1[i]])\n",
        "    txt_tar_tst.append(ns_txt_tar_tst[A1[i]])\n"
      ],
      "metadata": {
        "id": "5YwD-IEiVaLW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_inp.add(\" \")\n",
        "char_tar.add(\" \")\n",
        "char_inp = sorted(list(char_inp))\n",
        "char_tar = sorted(list(char_tar))"
      ],
      "metadata": {
        "id": "Sz44A2CJVaNt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_tok_num = len(char_inp)\n",
        "dec_tok_num = len(char_tar)"
      ],
      "metadata": {
        "id": "i0l1Rp1pfX-w"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_max_enc = max([len(txt) for txt in inps_txt])\n",
        "len_max_dec = max([len(txt) for txt in tars_txt])\n",
        "len_max_enc_tst = max([len(txt) for txt in inps_txt_tst])\n",
        "len_max_dec_tst = max([len(txt) for txt in inps_txt_tst])"
      ],
      "metadata": {
        "id": "lfHoPpa1VaQN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "n_gW0icY0s6A"
      },
      "outputs": [],
      "source": [
        "tok_ind_inp = dict([(j, k) for k, j in enumerate(char_inp)])\n",
        "tok_ind_tar = dict([(j, k) for k, j in enumerate(char_tar)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_source_char_index = dict((i, char) for char, i in tok_ind_inp.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in tok_ind_tar.items())"
      ],
      "metadata": {
        "id": "haUxrpLWiDMF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_txt_trnc = inps_txt[:44160]\n",
        "tar_txt_trnc = tars_txt[:44160]"
      ],
      "metadata": {
        "id": "p-llBIe2i3t2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_inp = np.zeros(\n",
        "            (len(inp_txt_trnc), len_max_enc, enc_tok_num), dtype=\"float64\")\n",
        "dec_tar = np.zeros(\n",
        "    (len(inp_txt_trnc), len_max_dec, dec_tok_num), dtype=\"float64\")"
      ],
      "metadata": {
        "id": "sewwBZepi6qW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (txt_inp, txt_tar) in enumerate(zip(inp_txt_trnc, tar_txt_trnc)):\n",
        "    for t, char in enumerate(txt_inp):\n",
        "        enc_inp[i, t, tok_ind_inp[char]] = 1.0\n",
        "    enc_inp[i, t + 1 :, tok_ind_inp[\" \"]] = 1.0\n",
        "    for t, char in enumerate(txt_tar):\n",
        "        dec_tar[i, t, tok_ind_tar[char]] = 1.0\n",
        "    dec_tar[i, t + 1 :, tok_ind_tar[\" \"]] = 1.0"
      ],
      "metadata": {
        "id": "APL4Y3HqkpzY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_tst_enc_dt = np.zeros(\n",
        "    (len(inps_txt_tst), len_max_enc, enc_tok_num), dtype=\"float64\"\n",
        ")\n",
        "tar_tst_dec_dt = np.zeros(\n",
        "    (len(txt_tar_tst), len_max_dec, dec_tok_num), dtype=\"float64\"\n",
        ")"
      ],
      "metadata": {
        "id": "OrSTL04Qkxyb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Fbk8Qwtd8Idu"
      },
      "outputs": [],
      "source": [
        "for i, (txt_inp, txt_tar) in enumerate(zip(inps_txt_tst, txt_tar_tst)):\n",
        "    for t, char in enumerate(txt_inp):\n",
        "        inp_tst_enc_dt[i, t, tok_ind_inp[char]] = 1.0\n",
        "    inp_tst_enc_dt[i, t + 1 :, tok_ind_inp[\" \"]] = 1.0\n",
        "\n",
        "    for t, char in enumerate(txt_tar):\n",
        "        tar_tst_dec_dt[i, t, tok_ind_tar[char]] = 1.0\n",
        "    tar_tst_dec_dt[i, t + 1: ,tok_ind_tar[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Siw3nJ7z8Ikk"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  \n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "    \n",
        "  def call(self, query, values):\n",
        "    \n",
        "    qt = tf.expand_dims(query, 1)\n",
        "    \n",
        "    sc = self.V(tf.nn.tanh(\n",
        "        self.W1(qt) + self.W2(values)))\n",
        "    \n",
        "    attn_wgt = tf.nn.softmax(sc, axis=1)\n",
        "    vec_cxt = attn_wgt * values\n",
        "    vec_cxt = tf.reduce_sum(vec_cxt, axis=1)\n",
        "\n",
        "    return vec_cxt, attn_wgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wHnKiZK48InE"
      },
      "outputs": [],
      "source": [
        "class model_with_attention(object):\n",
        "\n",
        "  def __init__(self, Type = 'RNN', hid_layer_size=32, l_r= 1e-3, drop_prob = 0.3, number_of_epochs = 10, batch_size = 32, attn = 'bahdanau'):\n",
        "    \n",
        "    self.Type = Type\n",
        "    self.hid_layer_size = hid_layer_size\n",
        "    self.l_r = l_r\n",
        "    self.drop_prob = drop_prob\n",
        "    self.number_of_epochs = number_of_epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.attn = attn\n",
        "\n",
        "    \n",
        "  def fit(self, enc_inp, dec_tar):\n",
        "\n",
        "    enc_inps = Input(shape=(len_max_enc, enc_tok_num), name='encoder_inputs')\n",
        "\n",
        "    if self.Type == 'LSTM':\n",
        "\n",
        "      enc_LSTM = LSTM(self.hid_layer_size,return_sequences=True, return_state=True, dropout = self.drop_prob, name='encoder_lstm')\n",
        "      enc_outs, hs, cs = enc_LSTM(enc_inps)\n",
        "      states_enc = [hs, cs]\n",
        "\n",
        "    elif self.Type == 'GRU':\n",
        "\n",
        "      enc_GRU = GRU(self.hid_layer_size,return_sequences=True, return_state=True, dropout = self.drop_prob, name='encoder_gru')\n",
        "      enc_outs, hs = enc_GRU(enc_inps)\n",
        "      states_enc = [hs]\n",
        "\n",
        "    elif self.Type == 'RNN':\n",
        "\n",
        "      enc_rnn = SimpleRNN(self.hid_layer_size,return_sequences=True, return_state=True, dropout = self.drop_prob, name='encoder_rnn')\n",
        "      enc_outs, hs = enc_rnn(enc_inps)\n",
        "      states_enc = [hs]\n",
        "\n",
        "    # Attention Layer\n",
        "    if self.attn == 'bahdanau':\n",
        "      attn= BahdanauAttention(self.hid_layer_size)\n",
        "\n",
        "    # Decoder Layers\n",
        "    inps_deco = Input(shape=(1, (dec_tok_num + self.hid_layer_size)),name='decoder_inputs')\n",
        "\n",
        "    if self.Type == 'LSTM':\n",
        "\n",
        "      dec_LSTM = LSTM(self.hid_layer_size, dropout = self.drop_prob, return_state=True, name='decoder_lstm')\n",
        "    \n",
        "    elif self.Type == 'GRU':\n",
        "\n",
        "      dec_GRU = GRU(self.hid_layer_size, dropout = self.drop_prob, return_state=True, name='decoder_gru')\n",
        "    \n",
        "    elif self.Type == 'RNN':\n",
        "\n",
        "      dec_RNN = SimpleRNN(self.hid_layer_size, dropout = self.drop_prob, return_state=True, name='decoder_rnn')  \n",
        "    \n",
        "    \n",
        "    dec_den = Dense(dec_tok_num, activation='softmax',  name='decoder_dense')\n",
        "    oa = []\n",
        "\n",
        "    ip = np.zeros((self.batch_size, 1, dec_tok_num))\n",
        "    ip[:, 0, 0] = 1 \n",
        "\n",
        "    dec_outs = hs\n",
        "    states = states_enc\n",
        "\n",
        "    for _ in range(len_max_dec):\n",
        "\n",
        "      vec_cxt, attn_wgt = attn(dec_outs, enc_outs)\n",
        "      vec_cxt = tf.expand_dims(vec_cxt, 1)\n",
        "      \n",
        "      ip = tf.concat([vec_cxt, ip], axis=-1)\n",
        "\n",
        "      if self.Type == 'LSTM':\n",
        "\n",
        "        dec_outs, h, c = dec_LSTM(ip, initial_state=states)\n",
        "\n",
        "      if self.Type == 'GRU':\n",
        "\n",
        "        dec_outs, h = dec_GRU(ip, initial_state=states)\n",
        "\n",
        "      if self.Type == 'RNN':\n",
        "\n",
        "        dec_outs, h = dec_RNN(ip, initial_state=states)\n",
        "      \n",
        "      op = dec_den(dec_outs)\n",
        "      op = tf.expand_dims(op, 1)\n",
        "      oa.append(op)\n",
        "      ip = op\n",
        "      if self.Type == 'LSTM':\n",
        "\n",
        "        states = [h, c]\n",
        "\n",
        "      if self.Type == 'GRU' or self.Type == 'RNN':\n",
        "        \n",
        "        states = [h]\n",
        "\n",
        "\n",
        "\n",
        "    dec_outs = Lambda(lambda x: K.concatenate(x, axis=1))(oa)\n",
        "    model = Model(enc_inps, dec_outs, name='model_encoder_decoder')\n",
        "    \n",
        "    optimizer = Adam(lr=self.l_r, beta_1=0.9, beta_2=0.999)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(enc_inp, dec_tar,\n",
        "              batch_size=self.batch_size, \n",
        "              epochs=self.number_of_epochs,\n",
        "              #callbacks = [WandbCallback()]\n",
        "              )\n",
        "\n",
        "    g_t = 0\n",
        "    g_c = 0\n",
        "    test_count = 4480\n",
        "\n",
        "    p = model.predict(inp_tst_enc_dt[:test_count], batch_size = self.batch_size)\n",
        "\n",
        "    data_list = [[\"SNO\", \"Input Data\", \"Target Data\", \"Predicted Data\"]]\n",
        "\n",
        "    for j in range(0,test_count):\n",
        "        p_v = p[j]\n",
        "        t_v = tar_tst_dec_dt[j]\n",
        "        p_i = tf.argmax(p_v, axis=1)\n",
        "        t_i = tf.argmax(t_v, axis=1)\n",
        "\n",
        "        if (p_i.numpy() == t_i.numpy()).all():\n",
        "            g_c = g_c + 1\n",
        "\n",
        "        g_t = g_t + 1\n",
        "\n",
        "        arr = p_i.numpy()\n",
        "        decoded_sequence = ''\n",
        "        for i in range(1,len(arr)):\n",
        "            if arr[i] != 2:\n",
        "                decoded_sequence = decoded_sequence + reverse_target_char_index[arr[i]]\n",
        "\n",
        "        t_w = txt_tar_tst[j] \n",
        "        t_w = t_w[1:len(t_w)-1]\n",
        "        dlist = [j+1, inps_txt_tst[j], t_w, decoded_sequence]\n",
        "        data_list.append(dlist)\n",
        "\n",
        "    with open('predictions_attention.tsv', 'w', newline='', encoding=\"utf-8\") as file:\n",
        "        writer = csv.writer(file, delimiter='\\t')\n",
        "        writer.writerows(data_list)\n",
        "\n",
        "    val_accuracy = g_c/g_t\n",
        "    print(val_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "h5mRiXnZ8IpV"
      },
      "outputs": [],
      "source": [
        "#best model\n",
        "best_attention = 'bahdanau'\n",
        "best_batch_size = 64\n",
        "best_cell_type = 'LSTM'\n",
        "best_dropout = 0.2\n",
        "best_epochs = 15\n",
        "best_hidden_size = 128\n",
        "best_learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Oe18d6hU8Irb"
      },
      "outputs": [],
      "source": [
        "model_rnn = model_with_attention(Type = best_cell_type, hid_layer_size = best_hidden_size, l_r = best_learning_rate,\n",
        "                                drop_prob = best_dropout, number_of_epochs = best_epochs, batch_size = best_batch_size, attn = best_attention)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQZXKsdh8Iti",
        "outputId": "b34d5d0a-4431-4a66-d747-f4efb3e2506c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "345/345 [==============================] - 56s 89ms/step - loss: 1.3418 - accuracy: 0.6788\n",
            "Epoch 2/15\n",
            "345/345 [==============================] - 31s 90ms/step - loss: 1.1049 - accuracy: 0.7052\n",
            "Epoch 3/15\n",
            "345/345 [==============================] - 31s 90ms/step - loss: 0.9701 - accuracy: 0.7301\n",
            "Epoch 4/15\n",
            "345/345 [==============================] - 31s 89ms/step - loss: 0.7220 - accuracy: 0.7849\n",
            "Epoch 5/15\n",
            "345/345 [==============================] - 31s 89ms/step - loss: 0.6225 - accuracy: 0.8092\n",
            "Epoch 6/15\n",
            "345/345 [==============================] - 31s 90ms/step - loss: 0.5851 - accuracy: 0.8177\n",
            "Epoch 7/15\n",
            "345/345 [==============================] - 31s 90ms/step - loss: 0.5583 - accuracy: 0.8242\n",
            "Epoch 8/15\n",
            "345/345 [==============================] - 31s 89ms/step - loss: 0.5401 - accuracy: 0.8295\n",
            "Epoch 9/15\n",
            "345/345 [==============================] - 31s 89ms/step - loss: 0.5266 - accuracy: 0.8334\n",
            "Epoch 10/15\n",
            "345/345 [==============================] - 31s 89ms/step - loss: 0.5091 - accuracy: 0.8382\n",
            "Epoch 11/15\n",
            "345/345 [==============================] - 31s 89ms/step - loss: 0.4983 - accuracy: 0.8412\n",
            "Epoch 12/15\n",
            "345/345 [==============================] - 31s 89ms/step - loss: 0.4887 - accuracy: 0.8435\n",
            "Epoch 13/15\n",
            "345/345 [==============================] - 31s 89ms/step - loss: 0.4788 - accuracy: 0.8465\n",
            "Epoch 14/15\n",
            "345/345 [==============================] - 31s 89ms/step - loss: 0.4721 - accuracy: 0.8484\n",
            "Epoch 15/15\n",
            "345/345 [==============================] - 31s 89ms/step - loss: 0.4630 - accuracy: 0.8515\n",
            "0.40799107142857144\n"
          ]
        }
      ],
      "source": [
        "model_rnn.fit(enc_inp,dec_tar)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rPHFDcP8zTwA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "seq2seq_attention_testing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}