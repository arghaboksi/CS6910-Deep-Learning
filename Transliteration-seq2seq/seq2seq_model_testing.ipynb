{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f9f25d77",
      "metadata": {
        "id": "f9f25d77"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import csv\n",
        "import keras\n",
        "import tensorflow \n",
        "import numpy as np\n",
        "from math import log, log1p \n",
        "from numpy import array, argmax\n",
        "from keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, GRU, Dropout, SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "ccd4c1e3",
      "metadata": {
        "id": "ccd4c1e3"
      },
      "outputs": [],
      "source": [
        "class seq2seq(object):\n",
        "    def __init__(self,Type = 'RNN',input_embedding = 32, hid_layer_size=32, lr= 1e-3, \n",
        "               drop_prob=0.4,prediction ='greedy', number_of_epochs = 10, batch_size = 32,beam_width = 5,\n",
        "               number_of_encoders = 1, number_of_decoders = 1):  \n",
        "    \n",
        "        self.Type = Type\n",
        "        self.input_embedding = input_embedding\n",
        "        self.hid_layer_size = hid_layer_size\n",
        "        self.lr = lr\n",
        "        self.drop_prob = drop_prob\n",
        "        self.prediction = prediction\n",
        "        self.number_of_epochs = number_of_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.beam_width = beam_width\n",
        "        self.number_of_encoders = number_of_encoders\n",
        "        self.number_of_decoders = number_of_decoders\n",
        "\n",
        "    def fit(self, enc_inp, dec_inp, dec_tar,x_test, y_test):\n",
        "\n",
        "        enc_inps = Input(shape=(None, ),name = 'Enc_inputs')\n",
        "\n",
        "        encoder_embedding =  Embedding(enc_tok_num, self.input_embedding , mask_zero = True,name = 'Enc_emb')(enc_inps)\n",
        "        \n",
        "        enc_outs = encoder_embedding\n",
        "\n",
        "        if self.Type == 'LSTM':\n",
        "\n",
        "            enc_LSTM = LSTM(self.hid_layer_size, return_state=True,dropout = self.drop_prob, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "            enc_outs, h, c = enc_LSTM(enc_outs)\n",
        "            states = [h, c]\n",
        "\n",
        "            for i in range( 2, self.number_of_encoders +1):\n",
        "\n",
        "                layer_name = ('Enc_hidden_%d') %i\n",
        "                enc_LSTM = LSTM(self.hid_layer_size, return_state=True,dropout = self.drop_prob, return_sequences=True, name=layer_name)\n",
        "                enc_outs, h, c = enc_LSTM(enc_outs,initial_state = states)\n",
        "                states = [h, c]\n",
        "\n",
        "        elif self.Type == 'GRU':\n",
        "\n",
        "            enc_GRU = GRU(self.hid_layer_size, return_state=True,dropout = self.drop_prob, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "            enc_outs, h = enc_GRU(enc_outs)\n",
        "            states = [h]\n",
        "\n",
        "            for i in range(2, self.number_of_encoders +1):\n",
        "\n",
        "                l = ('Enc_hidden_%d') %i\n",
        "                enc_GRU = GRU(self.hid_layer_size, return_state=True,dropout = self.drop_prob, return_sequences=True, name=l)\n",
        "                enc_outs, h = enc_GRU(enc_outs, initial_state = states)\n",
        "                states = [h]  \n",
        "\n",
        "        elif self.Type == 'RNN':\n",
        "\n",
        "            enc_rnn = SimpleRNN(self.hid_layer_size, return_state=True,dropout = self.drop_prob, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "            enc_outs, h = enc_rnn(enc_outs)\n",
        "            states = [h]\n",
        "            \n",
        "            for i in range(2, self.number_of_encoders +1):\n",
        "\n",
        "                l = ('Enc_hidden_%d') %i\n",
        "                enc_rnn = SimpleRNN(self.hid_layer_size, return_state=True,dropout = self.drop_prob, return_sequences=True, name=l)\n",
        "                enc_outs, h = enc_rnn(enc_outs, initial_state = states)\n",
        "                states = [h]  \n",
        "\n",
        "        dec_inps= Input(shape=(None,), name = 'Dec_inputs')\n",
        "        decoder_embedding_layer = Embedding(dec_tok_num, self.hid_layer_size, mask_zero = True, name = 'Dec_emb')\n",
        "        decoder_embedding = decoder_embedding_layer(dec_inps)\n",
        "        dec_outs = decoder_embedding\n",
        "\n",
        "        if self.Type == 'LSTM':\n",
        "\n",
        "            dec_LSTM = LSTM(self.hid_layer_size, return_sequences=True, return_state=True,dropout = self.drop_prob, name=\"Dec_hidden_1\")\n",
        "            dec_outs, _, _ = dec_LSTM(dec_outs, initial_state = states)\n",
        "\n",
        "            for i in range(2, self.number_of_decoders +1):\n",
        "\n",
        "                l = ('Dec_hidden_%d') %i\n",
        "                dec_LSTM = LSTM(self.hid_layer_size, return_sequences=True, return_state=True,dropout = self.drop_prob, name=l)\n",
        "                dec_outs, _, _ = dec_LSTM(dec_outs, initial_state = states)\n",
        "\n",
        "        elif self.Type == 'GRU':\n",
        "\n",
        "            dec_GRU = GRU(self.hid_layer_size, return_sequences=True, return_state=True,dropout = self.drop_prob, name=\"Dec_hidden_1\")\n",
        "            dec_outs, _ = dec_GRU(dec_outs, initial_state = states)\n",
        "\n",
        "            for i in range(2, self.number_of_decoders+1):\n",
        "\n",
        "                l = ('Dec_hidden_%d') %i\n",
        "                dec_GRU = GRU(self.hid_layer_size, return_sequences=True, return_state=True,dropout = self.drop_prob, name=l)\n",
        "                dec_outs, _ = dec_GRU(dec_outs, initial_state = states)\n",
        "\n",
        "        elif self.Type == 'RNN':\n",
        "\n",
        "            dec_RNN = SimpleRNN(self.hid_layer_size, return_sequences=True, return_state=True,dropout = self.drop_prob, name=\"Dec_hidden_1\")\n",
        "            dec_outs, _ = dec_RNN(dec_outs, initial_state = states)\n",
        "\n",
        "            for i in range(2, self.number_of_decoders+1):\n",
        "\n",
        "                l = ('Dec_hidden_%d') %i\n",
        "                dec_RNN = SimpleRNN(self.hid_layer_size, return_sequences=True, return_state=True,dropout = self.drop_prob, name=l)\n",
        "                dec_outs, _ = dec_RNN(dec_outs, initial_state = states)\n",
        "\n",
        "        den_dec= Dense(dec_tok_num, activation='softmax', name = 'dense')\n",
        "        dec_outs = den_dec(dec_outs)\n",
        "\n",
        "        \n",
        "        model = Model([enc_inps, dec_inps], dec_outs)\n",
        "        model.summary()\n",
        "        \n",
        "        optimizer = Adam(lr=self.lr, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "        model.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics=['accuracy'])\n",
        "\n",
        "        model.fit(\n",
        "            [enc_inp, dec_inp],\n",
        "            dec_tar,\n",
        "            batch_size=self.batch_size,\n",
        "            epochs=self.number_of_epochs,\n",
        "            )\n",
        "        \n",
        "        \n",
        "        enc_mod, dec_mod = self.inference(model)\n",
        "        data_list = [[\"SNO\", \"Input Data\", \"Target Data\", \"Predicted Data\"]]\n",
        "\n",
        "        g_t = 0\n",
        "        g_c = 0\n",
        "\n",
        "        for i in range(len(y_test)):\n",
        "          \n",
        "            input_seq = x_test[i : i + 1]\n",
        "            result = self.dec_seq(enc_mod,dec_mod,input_seq)\n",
        "            target = y_test[i]\n",
        "            target = target[1:len(target)-1]\n",
        "            result = result[0:len(result)-1]\n",
        "            dlist = [i+1, test_input_texts[i], target, result]\n",
        "            data_list.append(dlist)\n",
        "            if result.strip() == target.strip():\n",
        "                g_c = g_c + 1\n",
        "\n",
        "            g_t = g_t + 1\n",
        "            accuracy_epoch = g_c/g_t\n",
        "\n",
        "        with open('predictions_vanilla.tsv', 'w', newline='', encoding=\"utf-8\") as file:\n",
        "            writer = csv.writer(file, delimiter='\\t')\n",
        "            writer.writerows(data_list)\n",
        "        val_accuracy = g_c/g_t\n",
        "        print(val_accuracy)\n",
        "\n",
        "    \n",
        "    def inference(self, model):\n",
        "\n",
        "        enc_inps = model.input[0]  \n",
        "\n",
        "        if self.Type == 'RNN' or self.Type == 'GRU':\n",
        "\n",
        "            enc_outs, encoder_h = model.get_layer('Enc_hidden_'+ str(self.number_of_encoders)).output\n",
        "            states = [encoder_h]\n",
        "            enc_mod = Model(enc_inps, states)\n",
        "\n",
        "            dec_inps = model.input[1]  \n",
        "            dec_outs = model.get_layer('Dec_emb')(dec_inps)\n",
        "            inps_dec_states = []\n",
        "            dec_states = []\n",
        "\n",
        "            for i in range(1,self.number_of_decoders +1):\n",
        "\n",
        "                decoder_state_input_h = keras.Input(shape=(self.hid_layer_size,))\n",
        "                curr_states_inputs = [decoder_state_input_h]\n",
        "                decoder = model.get_layer('Dec_hidden_'+ str(i))\n",
        "                dec_outs, decoder_h = decoder(dec_outs, initial_state=curr_states_inputs)\n",
        "                dec_states += [decoder_h]\n",
        "                inps_dec_states += curr_states_inputs\n",
        "\n",
        "        elif self.Type == 'LSTM':\n",
        "\n",
        "            enc_outs, encoder_h, encoder_c = model.get_layer('Enc_hidden_'+ str(self.number_of_encoders)).output \n",
        "            states = [encoder_h, encoder_c]\n",
        "            enc_mod = Model(enc_inps, states)\n",
        "\n",
        "            dec_inps = model.input[1] \n",
        "            dec_outs = model.get_layer('Dec_emb')(dec_inps)\n",
        "            inps_dec_states = []\n",
        "            dec_states = []\n",
        "\n",
        "            for i in range(1,self.number_of_decoders +1):\n",
        "\n",
        "                decoder_state_input_h = keras.Input(shape=(self.hid_layer_size,))\n",
        "                decoder_state_input_c = keras.Input(shape=(self.hid_layer_size,))\n",
        "                curr_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "                decoder = model.get_layer('Dec_hidden_'+ str(i))\n",
        "                dec_outs, decoder_h, decoder_c = decoder(dec_outs, initial_state=curr_states_inputs)\n",
        "                dec_states += [decoder_h, decoder_c]\n",
        "                inps_dec_states += curr_states_inputs\n",
        "\n",
        "\n",
        "        den_dec = model.get_layer('dense')\n",
        "        dec_outs = den_dec(dec_outs)\n",
        "        dec_mod = Model([dec_inps] + inps_dec_states, [dec_outs] + dec_states)\n",
        "\n",
        "        return enc_mod,dec_mod\n",
        "\n",
        "\n",
        "    def search_beam(self,data, k):\n",
        "\n",
        "        seqs = [[list(), 0.0]]\n",
        "        for r in data:\n",
        "            a = list()\n",
        "            for i in range(len(seqs)):\n",
        "                seq, score = seqs[i]\n",
        "                for j in range(len(r)):\n",
        "                    c = [seq + [j], score - log(r[j])]\n",
        "                    a.append(c)\n",
        "        ord = sorted(a, key=lambda tup:tup[1])\n",
        "        seqs = ord[:k]\n",
        "        return seqs\n",
        "\n",
        "    def dec_seq(self,enc_mod,dec_mod,input_sequence):\n",
        "      \n",
        "        val_states = [enc_mod.predict(input_sequence)] * self.number_of_decoders\n",
        "        tar_sequence = np.zeros((1, 1))\n",
        "        tar_sequence[0, 0] = tok_ind_tar['B']\n",
        " \n",
        "        flag = False\n",
        "        decoded_sentence = \"\"\n",
        "\n",
        "        while not flag:\n",
        "\n",
        "            if self.Type == 'RNN' or self.Type == 'GRU':\n",
        "\n",
        "                d = dec_mod.predict([tar_sequence] + [val_states])\n",
        "                output_tokens, val_states = d[0],d[1:]\n",
        "\n",
        "            elif self.Type == 'LSTM':  \n",
        "\n",
        "                d = dec_mod.predict([tar_sequence] + val_states)\n",
        "                output_tokens, val_states = d[0],d[1:]\n",
        "\n",
        "            if self.prediction == 'greedy':\n",
        "                width_beam = 1\n",
        "            elif self.prediction == 'beam_search':\n",
        "                width_beam = self.beam_width\n",
        "\n",
        "            sampled_token_index = self.search_beam(output_tokens[0,:,:], width_beam)\n",
        "            sampled_token_index = sampled_token_index[width_beam-1][0]\n",
        "\n",
        "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "            sampled_char = rtci[sampled_token_index]\n",
        "            decoded_sentence += sampled_char\n",
        "\n",
        "            if sampled_char == 'E' or len(decoded_sentence) > max_decoder_seq_length:\n",
        "                flag = True\n",
        "\n",
        "            tar_sequence = np.zeros((1, 1))\n",
        "            tar_sequence[0, 0] = sampled_token_index\n",
        "\n",
        "        return decoded_sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "!yes | wget \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz8DZ3Q8sBUQ",
        "outputId": "734d2ac3-698e-4aa5-c92b-912d75681ab2"
      },
      "id": "Mz8DZ3Q8sBUQ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-08 03:25:55--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.148.128, 209.85.234.128, 172.217.212.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.148.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   124MB/s    in 11s     \n",
            "\n",
            "2022-05-08 03:26:06 (173 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip\n",
        "!yes | tar xopf dakshina_dataset_v1.0.tar"
      ],
      "metadata": {
        "id": "7yhvhrBhsH10"
      },
      "id": "7yhvhrBhsH10",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, Test and Validation Data\n",
        "!ls dakshina_dataset_v1.0/hi/lexicons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIXVpWb9sH7W",
        "outputId": "1c0ddc32-590d-44e6-c0a3-41d29ebfde0e"
      },
      "id": "DIXVpWb9sH7W",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi.translit.sampled.dev.tsv   hi.translit.sampled.train.tsv\n",
            "hi.translit.sampled.test.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
        "test_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\""
      ],
      "metadata": {
        "id": "2rByWmeJsH_r"
      },
      "id": "2rByWmeJsH_r",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reads text document and returns a list of lists comprising the romanized and native versions of the words\n",
        "def read(f):\n",
        "    hindi = []\n",
        "    latin = []\n",
        "    with io.open(f, encoding ='utf-8') as f:\n",
        "        for line in f:\n",
        "            if '\\t' not in line:\n",
        "                continue\n",
        "            tokens = line.rstrip().split(\"\\t\")\n",
        "            latin.append(tokens[1])\n",
        "            hindi.append(tokens[0])\n",
        "    return latin, hindi"
      ],
      "metadata": {
        "id": "55zb5cq5sIEW"
      },
      "id": "55zb5cq5sIEW",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_source, train_target = read(train_dir)\n",
        "test_source, test_target = read(test_dir)"
      ],
      "metadata": {
        "id": "gHk3w5RCsIG4"
      },
      "id": "gHk3w5RCsIG4",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.arange(len(train_source))\n",
        "np.random.shuffle(arr)\n",
        "arr1 = np.arange(len(test_source))\n",
        "np.random.shuffle(arr1)"
      ],
      "metadata": {
        "id": "2Nflh06VsIJJ"
      },
      "id": "2Nflh06VsIJJ",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_characters = set()\n",
        "target_characters = set()"
      ],
      "metadata": {
        "id": "n6pvch-osILd"
      },
      "id": "n6pvch-osILd",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ns_txt_inp = []\n",
        "ns_txt_tar = []\n",
        "test_input_texts_ns = []\n",
        "test_target_texts_ns = []"
      ],
      "metadata": {
        "id": "1EHZgGyvsINm"
      },
      "id": "1EHZgGyvsINm",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (input_text, txt_tar) in zip(train_source, train_target):\n",
        "    txt_tar = \"B\" + txt_tar + \"E\"\n",
        "    ns_txt_inp.append(input_text)\n",
        "    ns_txt_tar.append(txt_tar)\n",
        "    for char in input_text:\n",
        "        if char not in source_characters:\n",
        "            source_characters.add(char)\n",
        "    for char in txt_tar:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "metadata": {
        "id": "EkGmN9-VtnV5"
      },
      "id": "EkGmN9-VtnV5",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (input_text, txt_tar) in zip(test_source, test_target):\n",
        "    txt_tar = \"B\" + txt_tar + \"E\"\n",
        "    test_input_texts_ns.append(input_text)\n",
        "    test_target_texts_ns.append(txt_tar)\n",
        "    for char in input_text:\n",
        "        if char not in source_characters:\n",
        "            source_characters.add(char)\n",
        "    for char in txt_tar:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "metadata": {
        "id": "GVjUSqdeFJVn"
      },
      "id": "GVjUSqdeFJVn",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = []\n",
        "target_texts = []"
      ],
      "metadata": {
        "id": "g9EO7sy-tncV"
      },
      "id": "g9EO7sy-tncV",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input_texts = []\n",
        "txt_tar_tst = []"
      ],
      "metadata": {
        "id": "GB6C5mkBFXF1"
      },
      "id": "GB6C5mkBFXF1",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_source)):\n",
        "    input_texts.append(ns_txt_inp[arr[i]])\n",
        "    target_texts.append(ns_txt_tar[arr[i]])"
      ],
      "metadata": {
        "id": "LaqNsXgkFTj0"
      },
      "id": "LaqNsXgkFTj0",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_source)):\n",
        "    test_input_texts.append(test_input_texts_ns[arr1[i]])\n",
        "    txt_tar_tst.append(test_target_texts_ns[arr1[i]])"
      ],
      "metadata": {
        "id": "JlEzpUVsFUdn"
      },
      "id": "JlEzpUVsFUdn",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_characters.add(\" \")\n",
        "target_characters.add(\" \")"
      ],
      "metadata": {
        "id": "wAJmxOAttnjC"
      },
      "id": "wAJmxOAttnjC",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_characters = sorted(list(source_characters))\n",
        "target_characters = sorted(list(target_characters))"
      ],
      "metadata": {
        "id": "bjEyAE8XuE1L"
      },
      "id": "bjEyAE8XuE1L",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_tok_num = len(source_characters)\n",
        "dec_tok_num = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "test_max_encoder_seq_length = max([len(txt) for txt in test_input_texts])\n",
        "test_max_decoder_seq_length = max([len(txt) for txt in txt_tar_tst])"
      ],
      "metadata": {
        "id": "ONYUngTDuE6m"
      },
      "id": "ONYUngTDuE6m",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tok_ind_src = dict([(char, i) for i, char in enumerate(source_characters)])\n",
        "tok_ind_tar = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "reverse_source_char_index = dict((i, char) for char, i in tok_ind_src.items())\n",
        "rtci = dict((i, char) for char, i in tok_ind_tar.items())"
      ],
      "metadata": {
        "id": "vMqX_lQPuE9d"
      },
      "id": "vMqX_lQPuE9d",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_inp = np.zeros((len(input_texts), max_encoder_seq_length), dtype=\"float32\")\n",
        "dec_inp = np.zeros((len(input_texts), max_decoder_seq_length), dtype=\"float32\")\n",
        "dec_tar = np.zeros((len(input_texts), max_decoder_seq_length, dec_tok_num), dtype=\"float32\")"
      ],
      "metadata": {
        "id": "-gJXPdW3uE_y"
      },
      "id": "-gJXPdW3uE_y",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (input_text, txt_tar) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        enc_inp[i, t] = tok_ind_src[char]\n",
        "    enc_inp[i, t + 1 :] = tok_ind_src[\" \"]\n",
        "\n",
        "    for t, char in enumerate(txt_tar):\n",
        "        dec_inp[i, t] = tok_ind_tar[char]\n",
        "        if t > 0:\n",
        "            dec_tar[i, t - 1, tok_ind_tar[char]] = 1.0\n",
        "    dec_inp[i, t + 1: ] = tok_ind_tar[\" \"]\n",
        "    dec_tar[i, t:, tok_ind_tar[\" \"]] = 1.0"
      ],
      "metadata": {
        "id": "hc7wgWf0uFB6"
      },
      "id": "hc7wgWf0uFB6",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_tst_enc_data = np.zeros((len(input_texts), test_max_encoder_seq_length), dtype=\"float32\")\n",
        "dec_inp_tst_data = np.zeros((len(input_texts), test_max_decoder_seq_length), dtype=\"float32\")\n",
        "dec_tar_tst_data = np.zeros((len(input_texts), test_max_decoder_seq_length, dec_tok_num), dtype=\"float32\")"
      ],
      "metadata": {
        "id": "6pxTVrIhuFEP"
      },
      "id": "6pxTVrIhuFEP",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (input_text, txt_tar) in enumerate(zip(test_input_texts, txt_tar_tst)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        inp_tst_enc_data[i, t] = tok_ind_src[char]\n",
        "    inp_tst_enc_data[i, t + 1 :] = tok_ind_src[\" \"]\n",
        "\n",
        "    for t, char in enumerate(txt_tar):\n",
        "        dec_inp_tst_data[i, t] = tok_ind_tar[char]\n",
        "        if t > 0:\n",
        "            dec_tar_tst_data[i, t - 1, tok_ind_tar[char]] = 1.0\n",
        "    dec_inp_tst_data[i, t + 1: ] = tok_ind_tar[\" \"]\n",
        "    dec_tar_tst_data[i, t:, tok_ind_tar[\" \"]] = 1.0"
      ],
      "metadata": {
        "id": "jqk97-tLusAT"
      },
      "id": "jqk97-tLusAT",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "a729c62e",
      "metadata": {
        "id": "a729c62e"
      },
      "outputs": [],
      "source": [
        "x_test = inp_tst_enc_data\n",
        "y_test = txt_tar_tst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "7c7bb5d8",
      "metadata": {
        "id": "7c7bb5d8"
      },
      "outputs": [],
      "source": [
        "best_batch_size = 64\n",
        "best_beam_width = 3\n",
        "best_type = 'GRU'\n",
        "best_dec_search = 'greedy'\n",
        "best_dropout = 0.3\n",
        "best_epochs = 15\n",
        "best_hidden_size = 128\n",
        "best_in_emb = 256\n",
        "best_lr = 0.001\n",
        "best_num_dec = 1\n",
        "best_num_enc = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d16b791",
      "metadata": {
        "id": "2d16b791",
        "outputId": "87d00096-6f28-4c09-d20b-dbf360ac6721"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Enc_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_emb (Embedding)            (None, None, 256)    6912        ['Enc_inputs[0][0]']             \n",
            "                                                                                                  \n",
            " Dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_hidden_1 (GRU)             [(None, None, 128),  148224      ['Enc_emb[0][0]']                \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " Dec_emb (Embedding)            (None, None, 128)    8448        ['Dec_inputs[0][0]']             \n",
            "                                                                                                  \n",
            " Enc_hidden_2 (GRU)             [(None, None, 128),  99072       ['Enc_hidden_1[0][0]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_1[0][1]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_1 (GRU)             [(None, None, 128),  99072       ['Dec_emb[0][0]',                \n",
            "                                 (None, 128)]                     'Enc_hidden_2[0][1]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 66)     8514        ['Dec_hidden_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 370,242\n",
            "Trainable params: 370,242\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\729sh\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "691/691 [==============================] - 45s 40ms/step - loss: 0.8027 - accuracy: 0.4588\n",
            "Epoch 2/15\n",
            "691/691 [==============================] - 27s 39ms/step - loss: 0.3948 - accuracy: 0.6981\n",
            "Epoch 3/15\n",
            "691/691 [==============================] - 26s 37ms/step - loss: 0.2828 - accuracy: 0.7778\n",
            "Epoch 4/15\n",
            "691/691 [==============================] - 28s 41ms/step - loss: 0.2349 - accuracy: 0.8135\n",
            "Epoch 5/15\n",
            "691/691 [==============================] - 30s 43ms/step - loss: 0.2080 - accuracy: 0.8330\n",
            "Epoch 6/15\n",
            "691/691 [==============================] - 30s 43ms/step - loss: 0.1895 - accuracy: 0.8473\n",
            "Epoch 7/15\n",
            "691/691 [==============================] - 28s 41ms/step - loss: 0.1762 - accuracy: 0.8570\n",
            "Epoch 8/15\n",
            "691/691 [==============================] - 28s 41ms/step - loss: 0.1652 - accuracy: 0.8659\n",
            "Epoch 9/15\n",
            "691/691 [==============================] - 26s 38ms/step - loss: 0.1562 - accuracy: 0.8732\n",
            "Epoch 10/15\n",
            "691/691 [==============================] - 27s 39ms/step - loss: 0.1489 - accuracy: 0.8783\n",
            "Epoch 11/15\n",
            "691/691 [==============================] - 26s 38ms/step - loss: 0.1430 - accuracy: 0.8833\n",
            "Epoch 12/15\n",
            "691/691 [==============================] - 26s 38ms/step - loss: 0.1372 - accuracy: 0.8880\n",
            "Epoch 13/15\n",
            "691/691 [==============================] - 27s 39ms/step - loss: 0.1325 - accuracy: 0.8914\n",
            "Epoch 14/15\n",
            "691/691 [==============================] - 26s 38ms/step - loss: 0.1281 - accuracy: 0.8947\n",
            "Epoch 15/15\n",
            "691/691 [==============================] - 26s 38ms/step - loss: 0.1240 - accuracy: 0.8979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Enc_inputs, Dec_inputs with unsupported characters which will be renamed to enc_inputs, dec_inputs in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: s2s\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: s2s\\assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x0000023925E95248> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000002392C643108> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x00000239564A63C8> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3658374055975122\n"
          ]
        }
      ],
      "source": [
        "model_rnn = seq2seq(Type = best_type, input_embedding = best_in_emb, hid_layer_size=best_hidden_size,\n",
        "                lr= best_lr, drop_prob=best_dropout,prediction = best_dec_search, number_of_epochs = best_epochs,\n",
        "                batch_size = best_batch_size, beam_width = best_beam_width, number_of_encoders = best_num_enc, number_of_decoders = best_num_dec)\n",
        "  \n",
        "model_rnn.fit(enc_inp, dec_inp,dec_tar,x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6SPxz_mYFzkl"
      },
      "id": "6SPxz_mYFzkl",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "seq2seq_model_testing.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}