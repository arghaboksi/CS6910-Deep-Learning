{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9ZhrUeTDsx-"
      },
      "outputs": [],
      "source": [
        "# Necessary packages \n",
        "import io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from numpy import array, argmax, array_equal \n",
        "import keras.backend as K\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import models, Input\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, SimpleRNN, GRU, Dense, Flatten, TimeDistributed, RepeatVector, Lambda\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "tf.keras.backend.set_floatx('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx30eIrpN9SX",
        "outputId": "517f9142-47e5-465b-a749-9c9def782593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 56.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 56.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install wandb -q\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "ryRqR9hHpoU0",
        "outputId": "9a16af46-e1de-4d51-a81f-37e37766b4b8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "JCJVNoJzpsTd",
        "outputId": "db363443-93ce-4510-ced3-1a368592f99b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33margha\u001b[0m (\u001b[33mshubham-argha\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220504_090703-22ukfl7p</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/shubham-argha/Assignment%203/runs/22ukfl7p\" target=\"_blank\">ancient-fighter-156</a></strong> to <a href=\"https://wandb.ai/shubham-argha/Assignment%203\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/shubham-argha/Assignment%203/runs/22ukfl7p?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f8e72208050>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "wandb.init(project=\"Assignment 3\", entity=\"shubham-argha\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6dnebWKpu99",
        "outputId": "149beabc-c190-4e3a-d250-f21896cbabd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-04 09:07:22--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.125.128, 142.250.148.128, 108.177.112.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   213MB/s    in 9.0s    \n",
            "\n",
            "2022-05-04 09:07:31 (213 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Dataset\n",
        "!yes | wget \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcKy8CSEp_Mx"
      },
      "outputs": [],
      "source": [
        "# Unzip\n",
        "!yes | tar xopf dakshina_dataset_v1.0.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFMo0XNnqDq_",
        "outputId": "256464dd-b66a-4dd0-ffe4-9c4a37a39ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi.translit.sampled.dev.tsv   hi.translit.sampled.train.tsv\n",
            "hi.translit.sampled.test.tsv\n"
          ]
        }
      ],
      "source": [
        "# Train, Test and Validation Data\n",
        "!ls dakshina_dataset_v1.0/hi/lexicons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkG0hgUAqER_"
      },
      "outputs": [],
      "source": [
        "train_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
        "dev_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\"\n",
        "test_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBzvL2e20Sx-"
      },
      "outputs": [],
      "source": [
        "# reads text document and returns a list of lists comprising the romanized and native versions of the words\n",
        "def read(f):\n",
        "    hindi = []\n",
        "    latin = []\n",
        "    with io.open(f, encoding ='utf-8') as f:\n",
        "        for line in f:\n",
        "            if '\\t' not in line:\n",
        "                continue\n",
        "            tokens = line.rstrip().split(\"\\t\")\n",
        "            latin.append(tokens[1])\n",
        "            hindi.append(tokens[0])\n",
        "    return latin, hindi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-VCpVH93sFh"
      },
      "outputs": [],
      "source": [
        "tr_src, tr_tar = read(train_dir)\n",
        "val_src, val_tar = read(dev_dir)\n",
        "tst_src, tst_tar = read(test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GsuzoDm4BIo",
        "outputId": "4e6cd84d-3e18-41d2-9a30-5a29deda981b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples:  44204\n",
            "Number of validation samples:  4358\n",
            "Number of testing samples:  4502\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of training samples: \", len(tr_src))\n",
        "print(\"Number of validation samples: \", len(val_src))\n",
        "print(\"Number of testing samples: \", len(tst_src))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcpWebDU4o6_"
      },
      "outputs": [],
      "source": [
        "A = np.arange(len(tr_src))\n",
        "np.random.shuffle(A)\n",
        "A1 = np.arange(len(val_src))\n",
        "np.random.shuffle(A1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvnPFZvV4yKI"
      },
      "outputs": [],
      "source": [
        "char_inp = set()\n",
        "char_tar = set()\n",
        "ns_txt_inp = []\n",
        "ns_txt_tar = []\n",
        "ns_txt_inp_val = []\n",
        "ns_txt_tar_val = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u0pkPoq5GSq"
      },
      "outputs": [],
      "source": [
        "for (txt_inp, txt_tar) in zip(tr_src, tr_tar):\n",
        "    # tab : \"start sequence\" character\n",
        "    # \\n  : \"end sequence\" character\n",
        "    txt_tar = \"B\" + txt_tar + \"E\"\n",
        "    ns_txt_inp.append(txt_inp)\n",
        "    ns_txt_tar.append(txt_tar)\n",
        "\n",
        "    for char in txt_inp:\n",
        "        if char not in char_inp:\n",
        "            char_inp.add(char)\n",
        "\n",
        "    for char in txt_tar:\n",
        "        if char not in char_tar:\n",
        "            char_tar.add(char)\n",
        "\n",
        "\n",
        "for (txt_inp, txt_tar) in zip(val_src, val_tar):\n",
        "    # tab : \"start sequence\" character\n",
        "    # \\n  : \"end sequence\" character\n",
        "    txt_tar = \"B\" + txt_tar + \"E\"\n",
        "    ns_txt_inp_val.append(txt_inp)\n",
        "    ns_txt_tar_val.append(txt_tar)\n",
        "    for char in txt_inp:\n",
        "        if char not in char_inp:\n",
        "            char_inp.add(char)\n",
        "    for char in txt_tar:\n",
        "        if char not in char_tar:\n",
        "            char_tar.add(char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD6j9o7H5U1g"
      },
      "outputs": [],
      "source": [
        "inps_txt = []\n",
        "tars_txt = []\n",
        "\n",
        "for i in range(len(tr_src)):\n",
        "    inps_txt.append(ns_txt_inp[A[i]])\n",
        "    tars_txt.append(ns_txt_tar[A[i]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_inp_vals = []\n",
        "txt_tar_vals = []\n",
        "\n",
        "for i in range(len(val_src)):\n",
        "    txt_inp_vals.append(ns_txt_inp_val[A1[i]])\n",
        "    txt_tar_vals.append(ns_txt_tar_val[A1[i]])"
      ],
      "metadata": {
        "id": "5IslLeQE4K80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHadGBBO5oEW"
      },
      "outputs": [],
      "source": [
        "char_inp.add(\" \")\n",
        "char_tar.add(\" \")\n",
        "char_inp = sorted(list(char_inp))\n",
        "char_tar = sorted(list(char_tar))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_tok_num = len(char_inp)\n",
        "dec_tok_num= len(char_tar)"
      ],
      "metadata": {
        "id": "iMuAKfUb4W4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_max_enc = max([len(txt) for txt in inps_txt])\n",
        "len_max_dec = max([len(txt) for txt in tars_txt])\n",
        "len_max_enc_val = max([len(txt) for txt in txt_inp_vals])\n",
        "len_max_dec_val = max([len(txt) for txt in txt_tar_vals])"
      ],
      "metadata": {
        "id": "-MhTrTZG5Aqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtHaPQPw6VuP"
      },
      "outputs": [],
      "source": [
        "tok_ind_inp= dict([(j, k) for k, j in enumerate(char_inp)])\n",
        "tok_ind_tar= dict([(j, k) for k, j in enumerate(char_tar)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKb2WqwM6rUS",
        "outputId": "6112bd77-918c-42ba-d2d3-cc0ee523b0e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
            "{' ': 0, 'B': 1, 'E': 2, 'ँ': 3, 'ं': 4, 'ः': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ए': 13, 'ऐ': 14, 'ऑ': 15, 'ओ': 16, 'औ': 17, 'क': 18, 'ख': 19, 'ग': 20, 'घ': 21, 'ङ': 22, 'च': 23, 'छ': 24, 'ज': 25, 'झ': 26, 'ञ': 27, 'ट': 28, 'ठ': 29, 'ड': 30, 'ढ': 31, 'ण': 32, 'त': 33, 'थ': 34, 'द': 35, 'ध': 36, 'न': 37, 'प': 38, 'फ': 39, 'ब': 40, 'भ': 41, 'म': 42, 'य': 43, 'र': 44, 'ल': 45, 'व': 46, 'श': 47, 'ष': 48, 'स': 49, 'ह': 50, '़': 51, 'ा': 52, 'ि': 53, 'ी': 54, 'ु': 55, 'ू': 56, 'ृ': 57, 'ॅ': 58, 'े': 59, 'ै': 60, 'ॉ': 61, 'ो': 62, 'ौ': 63, '्': 64, 'ॐ': 65}\n"
          ]
        }
      ],
      "source": [
        "print(tok_ind_inp)\n",
        "print(tok_ind_tar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtAojV-O6p0G"
      },
      "outputs": [],
      "source": [
        "inp_txt_trnc = inps_txt[:44160]\n",
        "tar_txt_trnc = tars_txt[:44160]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31iEPN2D-UPA"
      },
      "outputs": [],
      "source": [
        "enc_inp = np.zeros(\n",
        "    (len(inp_txt_trnc), len_max_enc, enc_tok_num), dtype=\"float64\"\n",
        ")\n",
        "dec_tar = np.zeros(\n",
        "    (len(inp_txt_trnc), len_max_dec, dec_tok_num), dtype=\"float64\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCZN_YHH-ZeJ"
      },
      "outputs": [],
      "source": [
        "for i, (txt_inp, txt_tar) in enumerate(zip(inp_txt_trnc, tar_txt_trnc)):\n",
        "    for m, n in enumerate(txt_inp):\n",
        "        enc_inp[i, m, tok_ind_inp[n]] = 1.0\n",
        "    enc_inp[i, m + 1 :, tok_ind_inp[\" \"]] = 1.0\n",
        "    for m, n in enumerate(txt_tar):\n",
        "        dec_tar[i, m, tok_ind_tar[n]] = 1.0\n",
        "    dec_tar[i, m + 1 :, tok_ind_tar[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWmlTIC8-dTu"
      },
      "outputs": [],
      "source": [
        "inp_val_enc_dt = np.zeros(\n",
        "    (len(txt_inp_vals), len_max_enc, enc_tok_num), dtype=\"float64\"\n",
        ")\n",
        "tar_val_dec_dt = np.zeros(\n",
        "    (len(txt_tar_vals), len_max_dec, dec_tok_num), dtype=\"float64\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSyas_TA-gj1"
      },
      "outputs": [],
      "source": [
        "for i, (txt_inp, txt_tar) in enumerate(zip(txt_inp_vals, txt_tar_vals)):\n",
        "    \n",
        "    for t, n in enumerate(txt_inp):\n",
        "        inp_val_enc_dt[i, t, tok_ind_inp[n]] = 1.0\n",
        "    inp_val_enc_dt[i, t + 1 :, tok_ind_inp[\" \"]] = 1.0\n",
        "\n",
        "    for t, n in enumerate(txt_tar):\n",
        "        tar_val_dec_dt[i, t, tok_ind_tar[n]] = 1.0\n",
        "    tar_val_dec_dt[i, t + 1: , tok_ind_tar[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-RyyRhTQ2XC"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  \n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "    \n",
        "  def call(self, query, values):\n",
        "    \n",
        "    qt = tf.expand_dims(query, 1)\n",
        "    \n",
        "    sc = self.V(tf.nn.tanh(\n",
        "        self.W1(qt) + self.W2(values)))\n",
        "    \n",
        "    attn_wgt = tf.nn.softmax(sc, axis=1)\n",
        "    vec_cxt = attn_wgt * values\n",
        "    vec_cxt = tf.reduce_sum(vec_cxt, axis=1)\n",
        "\n",
        "    return vec_cxt, attn_wgt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mfk2-afoCeE"
      },
      "outputs": [],
      "source": [
        "class model_with_attention(object):\n",
        "\n",
        "  def __init__(self, Type = 'RNN', hid_layer_size=32, l_r= 1e-3, drop_prob = 0.3, number_of_epochs = 10, batch_size = 32, attn = 'bahdanau'):\n",
        "    \n",
        "    self.Type = Type\n",
        "    self.hid_layer_size = hid_layer_size\n",
        "    self.l_r = l_r\n",
        "    self.drop_prob = drop_prob\n",
        "    self.number_of_epochs = number_of_epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.attn = attn\n",
        "\n",
        "  def fit(self, enc_inp, dec_tar):\n",
        "\n",
        "    enc_inps = Input(shape=(len_max_enc, enc_tok_num), name='encoder_inputs')\n",
        "\n",
        "    if self.Type == 'LSTM':\n",
        "\n",
        "      enc_LSTM = LSTM(self.hid_layer_size,return_sequences=True, return_state=True, dropout = self.drop_prob, name='encoder_lstm')\n",
        "      enc_outs, hs, cs = enc_LSTM(enc_inps)\n",
        "      states_enc = [hs, cs]\n",
        "\n",
        "    elif self.Type == 'GRU':\n",
        "\n",
        "      enc_GRU = GRU(self.hid_layer_size,return_sequences=True, return_state=True, dropout = self.drop_prob, name='encoder_gru')\n",
        "      enc_outs, hs = enc_GRU(enc_inps)\n",
        "      states_enc = [hs]\n",
        "\n",
        "    elif self.Type == 'RNN':\n",
        "\n",
        "      enc_rnn = SimpleRNN(self.hid_layer_size,return_sequences=True, return_state=True, dropout = self.drop_prob, name='encoder_rnn')\n",
        "      enc_outs, hs = enc_rnn(enc_inps)\n",
        "      states_enc = [hs]\n",
        "\n",
        "    # Attention Layer\n",
        "    if self.attn == 'bahdanau':\n",
        "      attn= BahdanauAttention(self.hid_layer_size)\n",
        "\n",
        "    # Decoder Layers\n",
        "    inps_deco = Input(shape=(1, (dec_tok_num + self.hid_layer_size)),name='decoder_inputs')\n",
        "\n",
        "    if self.Type == 'LSTM':\n",
        "\n",
        "      dec_LSTM = LSTM(self.hid_layer_size, dropout = self.drop_prob, return_state=True, name='decoder_lstm')\n",
        "    \n",
        "    elif self.Type == 'GRU':\n",
        "\n",
        "      dec_GRU = GRU(self.hid_layer_size, dropout = self.drop_prob, return_state=True, name='decoder_gru')\n",
        "    \n",
        "    elif self.Type == 'RNN':\n",
        "\n",
        "      dec_RNN = SimpleRNN(self.hid_layer_size, dropout = self.drop_prob, return_state=True, name='decoder_rnn')  \n",
        "    \n",
        "    \n",
        "    dec_den = Dense(dec_tok_num, activation='softmax',  name='decoder_dense')\n",
        "    oa = []\n",
        "\n",
        "    ip = np.zeros((self.batch_size, 1, dec_tok_num))\n",
        "    ip[:, 0, 0] = 1 \n",
        "\n",
        "    dec_outs = hs\n",
        "    states = states_enc\n",
        "\n",
        "    for _ in range(len_max_dec):\n",
        "\n",
        "      vec_cxt, attn_wgt = attn(dec_outs, enc_outs)\n",
        "      vec_cxt = tf.expand_dims(vec_cxt, 1)\n",
        "      \n",
        "      ip = tf.concat([vec_cxt, ip], axis=-1)\n",
        "\n",
        "      if self.Type == 'LSTM':\n",
        "\n",
        "        dec_outs, h, c = dec_LSTM(ip, initial_state=states)\n",
        "\n",
        "      if self.Type == 'GRU':\n",
        "\n",
        "        dec_outs, h = dec_GRU(ip, initial_state=states)\n",
        "\n",
        "      if self.Type == 'RNN':\n",
        "\n",
        "        dec_outs, h = dec_RNN(ip, initial_state=states)\n",
        "      \n",
        "      op = dec_den(dec_outs)\n",
        "      op = tf.expand_dims(op, 1)\n",
        "      oa.append(op)\n",
        "      ip = op\n",
        "      if self.Type == 'LSTM':\n",
        "\n",
        "        states = [h, c]\n",
        "\n",
        "      if self.Type == 'GRU' or self.Type == 'RNN':\n",
        "        \n",
        "        states = [h]\n",
        "\n",
        "\n",
        "    dec_outs = Lambda(lambda x: K.concatenate(x, axis=1))(oa)\n",
        "    model = Model(enc_inps, dec_outs, name='model_encoder_decoder')\n",
        "    \n",
        "    optimizer = Adam(lr=self.l_r, beta_1=0.9, beta_2=0.999)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(enc_inp, dec_tar,\n",
        "              batch_size=self.batch_size, \n",
        "              epochs=self.number_of_epochs,\n",
        "              #callbacks = [WandbCallback()]\n",
        "              )\n",
        "\n",
        "    p = model.predict(inp_val_enc_dt[:4352], batch_size=self.batch_size)\n",
        "\n",
        "    ct = 0\n",
        "    g_t = 0\n",
        "    g_c = 0\n",
        "    v_t = 4352\n",
        "\n",
        "    for j in range(0, v_t):\n",
        "      \n",
        "      ohv = p[j]\n",
        "      ohv1 = tar_val_dec_dt[j]\n",
        "      j2 = tf.argmax(ohv, axis=1)\n",
        "      j1 = tf.argmax(ohv1, axis=1)\n",
        "      \n",
        "      if (j2.numpy() == j1.numpy()).all():\n",
        "        g_c = g_c + 1\n",
        "        \n",
        "      g_t = g_t + 1\n",
        "      accuracy_epoch = g_c/g_t\n",
        "\n",
        "      if g_t % 50 == 0:\n",
        "        wandb.log({'epoch_accuracy' : accuracy_epoch})\n",
        "    \n",
        "    val_accuracy = g_c/g_t\n",
        "    \n",
        "    wandb.log({'val_accuracy' : val_accuracy})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6v4kKgONH4q"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes', \n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "\n",
        "        'drop_prob': {\n",
        "            'values': [0.0, 0.1, 0.2]\n",
        "        },\n",
        "        'l_r': {\n",
        "            'values': [1e-3, 1e-4]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [64, 128]\n",
        "        },\n",
        "        'hid_layer_size':{\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'Type': {\n",
        "            'values': ['RNN', 'GRU', 'LSTM']\n",
        "        },\n",
        "        'attn': {\n",
        "            'values': ['bahdanau']    \n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC0C9Ol8QcW5",
        "outputId": "faa0c4fd-9adc-4461-ca33-6be9d250f001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: umcym8nf\n",
            "Sweep URL: https://wandb.ai/shubham-argha/Assignment%203/sweeps/umcym8nf\n"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, entity=\"shubham-argha\", project=\"Assignment 3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QeYGKXmlKHr"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "\n",
        "  config_defaults = {\n",
        "        'drop_prob': 0.3,\n",
        "        'l_r': 1e-3,\n",
        "        'batch_size': 128,\n",
        "        'number_of_epochs' : 15,\n",
        "        'hid_layer_size': 128,\n",
        "        'Type': 'LSTM',\n",
        "        'attn': 'bahdanau'\n",
        "        }\n",
        "\n",
        "  wandb.init(config = config_defaults)\n",
        "  \n",
        "  config = wandb.config\n",
        "\n",
        "  wandb.run.name = str(config.Type)+ '_' + config.attn +'_bs_'+str(config.batch_size)\n",
        "  \n",
        "  model_rnn = model_with_attention(Type = config.Type, hid_layer_size=config.hid_layer_size, l_r= config.l_r, drop_prob=config.drop_prob,epochs = config.number_of_epochs, batch_size = config.batch_size, attn = config.attn)\n",
        "  \n",
        "  model_rnn.fit(enc_inp, dec_tar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e0c1c26cb4fb447db8d26388810d204b",
            "9ad94b2b55874fd9b8050dfc98a0ba62",
            "06dad180172b44f195bdc3460d6e7e63",
            "c59c43dcca064650a36010646aa1d36f",
            "fba012a29ac2495991b42adb21314c16",
            "68c5e435b954443b9173579407d9a27b",
            "6f344c38c8ec4acbb069248af0d7347b",
            "9bec9994992447e7af3fc106263f482f"
          ]
        },
        "id": "kzx3bHH1_1M3",
        "outputId": "b9606b0a-051a-466c-82a5-1d0e24a85042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mh7obv5a with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tType: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention: bahdanau\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220504_075516-mh7obv5a</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/shubham-argha/Assignment%203/runs/mh7obv5a\" target=\"_blank\">visionary-sweep-19</a></strong> to <a href=\"https://wandb.ai/shubham-argha/Assignment%203\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/shubham-argha/Assignment%203/sweeps/jfhy1gz0\" target=\"_blank\">https://wandb.ai/shubham-argha/Assignment%203/sweeps/jfhy1gz0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "532/532 [==============================] - 97s 129ms/step - loss: 1.0652 - accuracy: 0.6989\n",
            "Epoch 2/15\n",
            "532/532 [==============================] - 69s 130ms/step - loss: 0.8219 - accuracy: 0.7455\n",
            "Epoch 3/15\n",
            "532/532 [==============================] - 69s 129ms/step - loss: 0.6703 - accuracy: 0.7926\n",
            "Epoch 4/15\n",
            "532/532 [==============================] - 69s 130ms/step - loss: 0.5962 - accuracy: 0.8204\n",
            "Epoch 5/15\n",
            "532/532 [==============================] - 69s 130ms/step - loss: 0.5552 - accuracy: 0.8355\n",
            "Epoch 6/15\n",
            "532/532 [==============================] - 68s 127ms/step - loss: 0.5316 - accuracy: 0.8428\n",
            "Epoch 7/15\n",
            "532/532 [==============================] - 68s 127ms/step - loss: 0.5165 - accuracy: 0.8483\n",
            "Epoch 8/15\n",
            "532/532 [==============================] - 68s 127ms/step - loss: 0.5054 - accuracy: 0.8518\n",
            "Epoch 9/15\n",
            "532/532 [==============================] - 69s 129ms/step - loss: 0.4955 - accuracy: 0.8546\n",
            "Epoch 10/15\n",
            "532/532 [==============================] - 68s 128ms/step - loss: 0.4860 - accuracy: 0.8574\n",
            "Epoch 11/15\n",
            "532/532 [==============================] - 68s 128ms/step - loss: 0.4811 - accuracy: 0.8589\n",
            "Epoch 12/15\n",
            "532/532 [==============================] - 68s 128ms/step - loss: 0.4727 - accuracy: 0.8613\n",
            "Epoch 13/15\n",
            "532/532 [==============================] - 67s 127ms/step - loss: 0.4683 - accuracy: 0.8628\n",
            "Epoch 14/15\n",
            "532/532 [==============================] - 67s 125ms/step - loss: 0.4663 - accuracy: 0.8635\n",
            "Epoch 15/15\n",
            "532/532 [==============================] - 67s 126ms/step - loss: 0.4594 - accuracy: 0.8659\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0c1c26cb4fb447db8d26388810d204b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_accuracy</td><td>██▄▂▁▁▃▃▁▂▄▄▅▅▆▆▇▇▆▆▆▆▆▇▇▇▇▇▇▇█▇▆▆▆▅▅▆▅▅</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_accuracy</td><td>0.43185</td></tr><tr><td>val_accuracy</td><td>0.43131</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">visionary-sweep-19</strong>: <a href=\"https://wandb.ai/shubham-argha/Assignment%203/runs/mh7obv5a\" target=\"_blank\">https://wandb.ai/shubham-argha/Assignment%203/runs/mh7obv5a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220504_075516-mh7obv5a/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: de5ox89m with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tType: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention: bahdanau\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220504_081320-de5ox89m</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/shubham-argha/Assignment%203/runs/de5ox89m\" target=\"_blank\">cerulean-sweep-20</a></strong> to <a href=\"https://wandb.ai/shubham-argha/Assignment%203\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/shubham-argha/Assignment%203/sweeps/jfhy1gz0\" target=\"_blank\">https://wandb.ai/shubham-argha/Assignment%203/sweeps/jfhy1gz0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "532/532 [==============================] - 170s 236ms/step - loss: 1.1791 - accuracy: 0.6838\n",
            "Epoch 2/15\n",
            "532/532 [==============================] - 126s 237ms/step - loss: 0.9718 - accuracy: 0.7105\n",
            "Epoch 3/15\n",
            "532/532 [==============================] - 126s 237ms/step - loss: 0.7848 - accuracy: 0.7525\n",
            "Epoch 4/15\n",
            "532/532 [==============================] - 126s 236ms/step - loss: 0.6460 - accuracy: 0.7973\n",
            "Epoch 5/15\n",
            "532/532 [==============================] - 126s 236ms/step - loss: 0.5776 - accuracy: 0.8226\n",
            "Epoch 6/15\n",
            "532/532 [==============================] - 125s 236ms/step - loss: 0.5444 - accuracy: 0.8344\n",
            "Epoch 7/15\n",
            "532/532 [==============================] - 126s 236ms/step - loss: 0.5222 - accuracy: 0.8416\n",
            "Epoch 8/15\n",
            "436/532 [=======================>......] - ETA: 22s - loss: 0.5068 - accuracy: 0.8461"
          ]
        }
      ],
      "source": [
        "wandb.agent(\"jfhy1gz0\", entity=\"shubham-argha\", project=\"Assignment 3\", function =train, count=10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "seq2seq_model_with_attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0c1c26cb4fb447db8d26388810d204b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ad94b2b55874fd9b8050dfc98a0ba62",
              "IPY_MODEL_06dad180172b44f195bdc3460d6e7e63"
            ],
            "layout": "IPY_MODEL_c59c43dcca064650a36010646aa1d36f"
          }
        },
        "9ad94b2b55874fd9b8050dfc98a0ba62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fba012a29ac2495991b42adb21314c16",
            "placeholder": "​",
            "style": "IPY_MODEL_68c5e435b954443b9173579407d9a27b",
            "value": "0.010 MB of 0.010 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "06dad180172b44f195bdc3460d6e7e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f344c38c8ec4acbb069248af0d7347b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9bec9994992447e7af3fc106263f482f",
            "value": 1
          }
        },
        "c59c43dcca064650a36010646aa1d36f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fba012a29ac2495991b42adb21314c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68c5e435b954443b9173579407d9a27b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f344c38c8ec4acbb069248af0d7347b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bec9994992447e7af3fc106263f482f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}